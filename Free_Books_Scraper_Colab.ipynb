{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# üìö Free Books Scraper - Google Colab Edition\n",
        "\n",
        "Scrape 1000+ free books from archive.org and Project Gutenberg with PDFs and HD covers!\n",
        "\n",
        "## üöÄ Quick Start\n",
        "1. Run the first cell to install dependencies\n",
        "2. Run the second cell to start scraping\n",
        "3. Wait 30-60 minutes for completion\n",
        "4. Use the third cell to explore your collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "print(\"üì¶ Installing required packages...\")\n",
        "!pip install requests beautifulsoup4 pandas lxml --quiet\n",
        "print(\"‚úÖ Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scraper"
      },
      "outputs": [],
      "source": [
        "# Download and run the book scraper\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download the scraper files\n",
        "!wget -q https://raw.githubusercontent.com/your-repo/book_scraper/main/book_scraper.py -O book_scraper.py\n",
        "!wget -q https://raw.githubusercontent.com/your-repo/book_scraper/main/book_utils.py -O book_utils.py\n",
        "\n",
        "print(\"üìö Starting Free Books Scraper...\")\n",
        "print(\"üéØ Target: 1000+ free books\")\n",
        "print(\"üìÇ Location: /content/books/\")\n",
        "print(\"‚è∞ Estimated time: 30-60 minutes\")\n",
        "print()\n",
        "\n",
        "# Run the scraper\n",
        "from book_scraper import BookScraper\n",
        "\n",
        "scraper = BookScraper(download_dir=\"/content/books\")\n",
        "books, csv_path, zip_path = scraper.run_full_scraping(target_books=1000)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ SCRAPING COMPLETED!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üìö Total books: {len(books)}\")\n",
        "print(f\"üìä Database: {csv_path}\")\n",
        "print(f\"üì¶ Zip file: {zip_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore"
      },
      "outputs": [],
      "source": [
        "# Explore your book collection\n",
        "import pandas as pd\n",
        "import os\n",
        "from book_utils import BookManager\n",
        "\n",
        "# Load the collection\n",
        "manager = BookManager(\"/content/books\")\n",
        "df = manager.df\n",
        "\n",
        "print(\"üìä COLLECTION OVERVIEW\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Total books: {len(df)}\")\n",
        "print(f\"Books with PDFs: {len(df[df['local_pdf_path'] != ''])}\")\n",
        "print(f\"Books with covers: {len(df[df['local_cover_path'] != ''])}\")\n",
        "\n",
        "# Show sample books\n",
        "print(\"\\nüìñ SAMPLE BOOKS:\")\n",
        "sample = df[['title', 'author', 'categories']].head(5)\n",
        "for i, (_, book) in enumerate(sample.iterrows()):\n",
        "    print(f\"{i+1}. {book['title']} by {book['author']}\")\n",
        "    print(f\"   üìÇ {book['categories']}\")\n",
        "\n",
        "# Show file sizes\n",
        "if os.path.exists(csv_path):\n",
        "    csv_size = os.path.getsize(csv_path) / (1024*1024)\n",
        "    print(f\"\\nüìÑ CSV file size: {csv_size:.2f} MB\")\n",
        "\n",
        "if os.path.exists(zip_path):\n",
        "    zip_size = os.path.getsize(zip_path) / (1024*1024)\n",
        "    print(f\"üì¶ Zip file size: {zip_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "search"
      },
      "outputs": [],
      "source": [
        "# Search and browse your collection\n",
        "print(\"üîç SEARCH EXAMPLES\")\n",
        "print(\"=\"*30)\n",
        "\n",
        "# Search by title\n",
        "python_books = manager.search_books('Python')\n",
        "print(f\"\\nüêç Python books ({len(python_books)}):\")\n",
        "for i, (_, book) in enumerate(python_books.head(3).iterrows()):\n",
        "    print(f\"  {i+1}. {book['title']}\")\n",
        "\n",
        "# Browse by category\n",
        "fiction_books = manager.get_books_by_category('Fiction')\n",
        "print(f\"\\nüìö Fiction books ({len(fiction_books)}):\")\n",
        "for i, (_, book) in enumerate(fiction_books.head(3).iterrows()):\n",
        "    print(f\"  {i+1}. {book['title']} ({book['date']})\")\n",
        "\n",
        "# Most popular\n",
        "popular = manager.get_most_popular(5)\n",
        "print(f\"\\n‚≠ê Most popular books:\")\n",
        "for i, (_, book) in enumerate(popular.iterrows()):\n",
        "    print(f\"  {i+1}. {book['title']} (üìä {book['download_count']:,} downloads)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "# Download files from Colab\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üíæ DOWNLOAD FILES\")\n",
        "print(\"=\"*25)\n",
        "\n",
        "# Download CSV database\n",
        "print(\"üìä Downloading CSV database...\")\n",
        "files.download(csv_path)\n",
        "\n",
        "# Download zip archive\n",
        "print(\"üì¶ Downloading zip archive...\")\n",
        "files.download(zip_path)\n",
        "\n",
        "print(\"\\n‚úÖ Files downloaded to your computer!\")\n",
        "print(\"üí° You can also find them in the Colab file browser (left sidebar)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usage"
      },
      "source": [
        "## üìñ How to Use Your Collection\n",
        "\n",
        "### Load the Database\n",
        "```python\n",
        "import pandas as pd\n",
        "df = pd.read_csv('books_database.csv')\n",
        "```\n",
        "\n",
        "### Find Books\n",
        "```python\n",
        "# Search by title\n",
        "python_books = df[df['title'].str.contains('Python', case=False)]\n",
        "\n",
        "# Filter by category\n",
        "fiction = df[df['categories'].str.contains('Fiction', case=False)]\n",
        "\n",
        "# Most popular\n",
        "popular = df.nlargest(10, 'download_count')\n",
        "```\n",
        "\n",
        "### Access Files\n",
        "```python\n",
        "# Get first book\n",
        "book = df.iloc[0]\n",
        "\n",
        "# PDF path\n",
        "pdf_path = book['local_pdf_path']\n",
        "\n",
        "# Cover path\n",
        "cover_path = book['local_cover_path']\n",
        "```\n",
        "\n",
        "### File Structure\n",
        "```\n",
        "/content/books/\n",
        "‚îú‚îÄ‚îÄ books_database.csv       # Complete database\n",
        "‚îú‚îÄ‚îÄ free_books_collection.zip # All files zipped\n",
        "‚îú‚îÄ‚îÄ pdfs/                    # Downloaded PDFs\n",
        "‚îú‚îÄ‚îÄ covers/                  # HD covers\n",
        "‚îî‚îÄ‚îÄ metadata/                # Statistics\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Free Books Scraper",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}